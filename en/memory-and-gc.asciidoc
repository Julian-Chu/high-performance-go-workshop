[#memory-and-gc]
= Memory and Garbage Collector

Go is a garbage collected language.
This is a design principle, it will not change.

As a garbage collected language, the performance of Go programs is often determined by their interaction with the garbage collector.

Next to your choice of algorithms, memory consumption is the most important factor that determines the performance and scalability of your application.

This section discusses the operation of the garbage collector, how to measure the memory usage of your program and strategies for lowering memory usage if garbage collector performance is a bottleneck.

== Garbage collector world view

The purpose of any garbage collector is to present the illusion that there is an infinite amount of memory available to the program.

You may disagree with this statement, but this is the base assumption of how garbage collector designers work.

A stop the world, mark sweep GC is the most efficient in terms of total run time; good for batch processing, simulation, etc.
However, over time the Go GC has moved from a pure stop the world collector to a concurrent, non compacting, collector.
This is because the Go GC is designed for low latency servers and interactive applications.

The design of the Go GC favors _lower_latency_ over _maximum_throughput_; it moves some of the allocation cost to the mutator to reduce the cost of cleanup later.

== Garbage collector design

The design of the Go GC has changed over the years

- Go 1.0, stop the world mark sweep collector based heavily on tcmalloc.
- Go 1.3, fully precise collector, wouldn't mistake big numbers on the heap for pointers, thus leaking memory.
- Go 1.5, new GC design, focusing on _latency_ over _throughput_.
- Go 1.6, GC improvements, handling larger heaps with lower latency.
- Go 1.7, small GC improvements, mainly refactoring.
- Go 1.8, further work to reduce STW times, now down to the 100 microsecond range.
- Go 1.10+, https://github.com/golang/proposal/blob/master/design/24543-non-cooperative-preemption.md[move away from pure cooprerative goroutine scheduling] to lower the latency when triggering a full GC cycle.
- Go 1.13 Scavenger rewritten

=== Garbage collector tuning

The Go runtime provides one environment variable to tune the GC, `GOGC`.

The formula for GOGC is

stem:[goal = reachabl\e * (1 + (GOGC)/100)]

For example, if we currently have a 256MB heap, and `GOGC=100` (the default), when the heap fills up it will grow to

stem:[512MB = 256MB * (1 + 100/100)]

- Values of `GOGC` greater than 100 causes the heap to grow faster, reducing the pressure on the GC.
- Values of `GOGC` less than 100 cause the heap to grow slowly, increasing the pressure on the GC.

The default value of 100 is _just_a_guide_. you should choose your own value _after profiling your application with production loads_.

=== VSS and the scavenger

Many applications operate through distict phases; setup, steady-state, and (optionally) shutdown.
The phases have different memory profiles.
Setup may process or summarise a large amounts of data.
Steady-state may consume memory proportional to connected clients or request rate.
Shutdown may consume memory proportional to the amount of data process during steady state to summarise or pasivate data to disk.

In practical terms your application may use more memory on startup than during the rest of it's life, then its heap will be larger than necessary, but mostly unused.
It would be useful if the Go runtime could tell the operating system which parts of the, mostly unoccupied, heap are not needed.

[TIP]
.New in Go 1.13
====
The scavenger has remained mostly unchanged since it was first implemented in Go 1.1.
In Go 1.13 scavenging moves from a periodic background operation to something demand driven, thus processes which do not benefit from scavenging do not pay for it where as long running programs where memory allocation varys widely _should_ return memory to the operating system more effectively.

_However_, some of the CLs related to scavenging have not been committed.
It is possible that this work will not be completed until Go 1.14.

Further reading
- https://github.com/golang/go/issues/30333[Issue #30333]
- https://github.com/golang/proposal/blob/master/design/30333-smarter-scavenging.md[Smarter scavenging design document].
====
////
talk about scavenger
talk about changes in go 1.13
talk about effect on VSS vs RSS
talk about the heap being non contigioius now
talk about reading memstats not top for the _real_ information.
////

=== Garbage collector monitoring

A simple way to obtain a general idea of how hard the garbage collector is working is to enable the output of GC logging.

These stats are always collected, but normally suppressed, you can enable their display by setting the `GODEBUG` environment variable.

[source,options=nowrap]
% env GODEBUG=gctrace=1 godoc -http=:8080
gc 1 @0.012s 2%: 0.026+0.39+0.10 ms clock, 0.21+0.88/0.52/0+0.84 ms cpu, 4->4->0 MB, 5 MB goal, 8 P
gc 2 @0.016s 3%: 0.038+0.41+0.042 ms clock, 0.30+1.2/0.59/0+0.33 ms cpu, 4->4->1 MB, 5 MB goal, 8 P
gc 3 @0.020s 4%: 0.054+0.56+0.054 ms clock, 0.43+1.0/0.59/0+0.43 ms cpu, 4->4->1 MB, 5 MB goal, 8 P
gc 4 @0.025s 4%: 0.043+0.52+0.058 ms clock, 0.34+1.3/0.64/0+0.46 ms cpu, 4->4->1 MB, 5 MB goal, 8 P
gc 5 @0.029s 5%: 0.058+0.64+0.053 ms clock, 0.46+1.3/0.89/0+0.42 ms cpu, 4->4->1 MB, 5 MB goal, 8 P
gc 6 @0.034s 5%: 0.062+0.42+0.050 ms clock, 0.50+1.2/0.63/0+0.40 ms cpu, 4->4->1 MB, 5 MB goal, 8 P
gc 7 @0.038s 6%: 0.057+0.47+0.046 ms clock, 0.46+1.2/0.67/0+0.37 ms cpu, 4->4->1 MB, 5 MB goal, 8 P
gc 8 @0.041s 6%: 0.049+0.42+0.057 ms clock, 0.39+1.1/0.57/0+0.46 ms cpu, 4->4->1 MB, 5 MB goal, 8 P
gc 9 @0.045s 6%: 0.047+0.38+0.042 ms clock, 0.37+0.94/0.61/0+0.33 ms cpu, 4->4->1 MB, 5 MB goal, 8 P

The trace output gives a general measure of GC activity.
The output format of `gctrace=1` is described in https://golang.org/pkg/runtime/#hdr-Environment_Variables[the `runtime` package documentation].

DEMO: Show `godoc` with `GODEBUG=gctrace=1` enabled

TIP: Use this env var in production, it has no performance impact.

Using `GODEBUG=gctrace=1` is good when you _know_ there is a problem, but for general telemetry on your Go application I recommend the `net/http/pprof` interface.

[source]
import _ "net/http/pprof"

Importing the `net/http/pprof` package will register a handler at `/debug/pprof` with various runtime metrics, including:

- A list of all the running goroutines, `/debug/pprof/heap?debug=1`. 
- A report on the memory allocation statistics, `/debug/pprof/heap?debug=1`.

[WARNING]
====
`net/http/pprof` will register itself with your default `http.ServeMux`.

Be careful as this will be visible if you use `http.ListenAndServe(address, nil)`.
====

DEMO: `godoc -http=:8080`, show `/debug/pprof`.

== Minimise allocations

Memory allocation is not free, this is true reguardless of if your language is garbage collected or not.

Memory allocation can be an overhead spread throughout your codebase; each represents a tiny fraction of the total runtime, but collectively they represent a sizeable cost.
Because that cost is spread across many places, identifying the biggest offenders can be complicated and often requires reworking APIs.

Each allocation should pay its way.
Analogy: if you move to a larger house because you're planning on having a family, that's a good use of your capital.
If you move to a larger house because someone asked you to mind their child for an afternoon, that's a poor use of your capital.

=== ``string``s vs ``[]byte``s

In Go `string` values are immutable, `[]byte` are mutable.

Most programs prefer to work `string`, but most IO is done with `[]byte`.

Avoid `[]byte` to string conversions wherever possible, this normally means picking one representation, either a `string` or a `[]byte` for a value.
Often this will be `[]byte` if you read the data from the network or disk.

The https://golang.org/pkg/bytes/[`bytes`] package contains many of the same operations -- `Split`, `Compare`, `HasPrefix`, `Trim`, etc -- as the https://golang.org/pkg/strings/[`strings`] package.

Under the hood `strings` uses same assembly primitives as the `bytes` package.

=== Using ``[]byte`` as a map key

It is very common to use a `string` as a map key, but often you have a `[]byte`.
Alterntative you may have a key in `[]byte` form, but slices do not have a defined equality operator so cannot be used as map keys.

The compiler implements a specific optimisation for this case

[source,go]
var m map[string]string
v, ok := m[string(bytes)]

This will avoid the conversion of the byte slice to a string for the map lookup. This is very specific, it won't work if you do something like

[source]
key := string(bytes)
val, ok := m[key] 

====
Let's see if this is still true.
Write a benchmark comparing these two methods of using a `[]byte` as a `string` map key.
====

=== `[]byte` to `string` conversions

TIP: New in Go 1.13

Just like `[]byte` to `string` conversions are necessary for map keys, comparing two `[]byte` slices for equality either requires a conversion -- potentially a copy -- to a `string`, or the use of the `bytes.Equal` function.

The good news is in 1.13 the compiler has improved to the point that `[]byte` to `string` conversions for the purpose of equality testing avoids the allocation.

[source,go,options=nowrap]
----
include::../examples/byteseq/bytes_test.go[tags=bench]
----
However, just like the map example above, the copy is only elided in simple cases.

Further reading: https://go-review.googlesource.com/c/go/+/173323

=== Avoid string concatenation

Go strings are immutable. Concatenating two strings generates a third. Which of the following is fastest? 

[source,go,options=nowrap]
include::../examples/concat/concat_test.go[tags=one]

[source,go,options=nowrap]
include::../examples/concat/concat_test.go[tags=two]

[source,go,options=nowrap]
include::../examples/concat/concat_test.go[tags=three]

[source,go,options=nowrap]
include::../examples/concat/concat_test.go[tags=four]

[source,go,options=nowrap]
include::../examples/concat/concat_test.go[tags=five]

DEMO: `go test -bench=. ./examples/concat`

=== Don't force allocations on the callers of your API

Make sure your APIs allow the caller to reduce the amount of garbage generated.

Consider these two Read methods

[source,go]
func (r *Reader) Read() ([]byte, error)
func (r *Reader) Read(buf []byte) (int, error)

The first Read method takes no arguments and returns some data as a `[]byte`.
The second takes a `[]byte` buffer and returns the amount of bytes read.

The first Read method will _always_ allocate a buffer, putting pressure on the GC. The second fills the buffer it was given.

====
Can you name examples in the std lib which follow this pattern?
====

=== Preallocate slices if the length is known

Append is convenient, but wasteful.

Slices grow by doubling up to 1024 elements, then by approximately 25% after that. What is the capacity of `b` after we append one more item to it?

[source,go,options=nowrap]
----
include::../examples/grow/grow.go[tags=main]
----

If you use the append pattern you could be copying a lot of data and creating a lot of garbage.

If know know the length of the slice beforehand, then pre-allocate the target to avoid copying and to make sure the target is exactly the right size. 

[source,go]
.Before
----
var s []string
for _, v := range fn() {
        s = append(s, v)
}
return s
----

[source,go]
.After
----
vals := fn()
s := make([]string, len(vals))
for i, v := range vals {
        s[i] = v           
}
return s
----

== Using sync.Pool

WARNING: `sync.Pool` is not a cache. It can and will be emptied _at_any_time_. Do not place important items in a `sync.Pool`, they will be discarded.

The `sync` package comes with a `sync.Pool` type which is used to reuse common objects.

`sync.Pool` has no fixed size or maximum capacity.
You add to it and take from it until a GC happens, then it is emptied unconditionally.
This is https://groups.google.com/forum/#!searchin/golang-dev/gc-aware/golang-dev/kJ_R6vYVYHU/LjoGriFTYxMJ[by design]:

> If before garbage collection is too early and after garbage collection too late, then the right time to drain the pool must be during garbage collection. That is, the semantics of the Pool type must be that it drains at each garbage collection. -- Russ Cox

[source,go,options=nowrap]
.sync.Pool in action
----
include::../examples/pool/pool.go[tags=pool]
----

[TIP]
.New in Go 1.13
====
The design of sync.Pool emptying itself on each GC may change in Go 1.13 which will help improve its utility.

> This CL fixes this by introducing a victim cache mechanism. Instead of
clearing Pools, the victim cache is dropped and the primary cache is
moved to the victim cache. As a result, in steady-state, there are
(roughly) no new allocations, but if Pool usage drops, objects will
still be collected within two GCs (as opposed to one). -- Austin Clements

Further reading:
- https://go-review.googlesource.com/c/go/+/166961/
- https://github.com/golang/go/issues/22331
====

== Rearrange fields for better packing

Consider this struct declaration
[source,go,options=nowrap]
----
include::../examples/fields/fields.go[tags=struct]
----
How many bytes of memory does a value of this type consume?
[source,go,option=nowrap]
----
include::../examples/fields/fields.go[tags=sizeof]
----
<1> 24 bytes on 64-bit platforms, 16 on 32-bit platforms.

Why is this? The answer has to do with padding and alignment.

Values of type `float64` are 8 bytes wide on all platforms, so they must always be located at an address that is a multiple of 8.
This is known as _natural alignment_, as the CPU naturally expects fields which are 4 bytes long to be alligned on 4 byte boundaries, 8 byte values on 8 byte boundaries, and so on.
This is because some platforms, notably _not_ Intel, do not let you operate on values that are not properly aligned.
Even on platforms that do support so called _unaligned access_, there is usually a cost to access these fields.

WARNING: Even on platforms that allow unaligned access, `sync/atomic` requires the values be naturally aligned. This is because atomic operations are implemented in the various L1, L2, L3 caching layers, which always work in amounts known as cache lines (normally 32-64 bytes wide). Atomic access cannot span cache lines, so they must be correctly aligned. This is the infamous https://golang.org/issue/599[issue 599].

Knowing how alignment works, we can infer how the compiler is going to lay out these fields in memory:
[source,go,option=nowrap]
----
include::../examples/fields/fields.go[tags=padding]
----
<1> 7 bytes of padding is required to ensure `b float64` starts on an 8 byte boundary.
<2> 4 bytes of padding are required to ensure that arrays (or slices) of ``S``'s are correctly aligned in memory.
 
http://golang-sizeof.tips/?t=Ly8gU2FtcGxlIGNvZGUKc3RydWN0IHsKCWEgYm9vbAoJYiBmbG9hdDY0CgljIGludDMyCn0K[There's even a web service for this!]

====
_Exercise_: rearrange the fields in `S` to reduce its overall size.
====

Further reading: https://dave.cheney.net/2015/10/09/padding-is-hard[Padding is hard]

== Exercises

- Using `godoc` (or another program) observe the results of changing `GOGC` using `GODEBUG=gctrace=1`.
- Benchmark byte's string(byte) map keys
- Benchmark allocs from different concat strategies.